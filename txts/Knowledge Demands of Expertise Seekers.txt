Decision Support Systems 53 (2012) 482–489

Contents lists available at SciVerse ScienceDirect

Decision Support Systems

j o u r na l h o me p a g e : ww w . e l s e v i e r . c o m / l oc a t e / d s s

The knowledge demands of expertise seekers in two different contexts: Knowledge
allocation versus knowledge retrieval
Dorit Nevo a,⁎, Izak Benbasat b, Yair Wand b
a Schulich School of Business, York University, Canada
b Sauder School of Business, University of British Columbia, Canada

a r t i c l e

i n f o

a b s t r a c t

Article history:
Received 2 February 2011
Received in revised form 22 December 2011
Accepted 19 March 2012
Available online 29 March 2012

Keywords:
Expertise location
Knowledge allocation
Knowledge retrieval
Information systems
Expert selection decision

1. Introduction

This paper explores the knowledge demands of expertise seekers for the purpose of designing effective
expertise locator systems. We conduct an empirical investigation, using conjoint analysis and within-subject
tests, to determine the relative importance assigned to different expert attributes under two expertise
seeking contexts: knowledge allocation and knowledge retrieval. Our results show that when choosing an
expert to retrieve knowledge from (knowledge retrieval), expertise seekers will assign greater importance to
the person's level of expertise. When selecting an expert to transfer knowledge to (knowledge allocation),
attributes representing the network ties between the expert and the seeker as well as the benevolence of the
expert will be perceived as more important. These results are important for the design of expertise locator
systems that are better customized to ﬁt the knowledge needs of their users, and to serve the organization as
a whole.

© 2012 Elsevier B.V. All rights reserved.

Organization members possess unique expertise that beneﬁts the
organization by enabling improved work processes, decision-making,
knowledge synergies, and innovation. Indeed, organizational innova-
tion often entails the combination of people and knowledge, creating
new connections between people and their ideas and resources such
that new combinations emerge [33]. Locating where this expertise
resides and coordinating its utilization are therefore of great
importance to organizations.

However, these activities are also quite challenging. For example, a
survey of professionals in medium and large companies (with 1000 or
more employees) revealed that when it comes to locating expertise,
about one third did not know of people in the company who may
potentially help them to do their job better; moreover, 61% could not
locate these people [10]. Studies on strategies applied in locating expertise
have shown that people tend to look in their vicinity, examine historical
documents, or, as organizations grow and become more dispersed, turn to
connectors (sometimes referred to as “expertise concierges”) to identify
potential experts [2,27]. Consequently, expertise locator systems –
information systems designed to support the identiﬁcation and location
of organizational expertise – are increasingly being utilized in organiza-
tions, albeit with numerous challenges and limited success [2,17,27,45].
Indeed, locating expertise in organizations is not an easy task.
Searching for experts beyond one's immediate group of colleagues

⁎ Corresponding author.

E-mail addresses: dnevo@schulich.yorku.ca (D. Nevo), izak.benbasat@ubc.ca

(I. Benbasat), yair.wand@ubc.ca (Y. Wand).

0167-9236/$ – see front matter © 2012 Elsevier B.V. All rights reserved.
doi:10.1016/j.dss.2012.03.005

requires, ﬁrst and foremost, having knowledge of who knows what in
the organization and being able to track expertise as employees develop
skills, join and leave the organization, and take on new tasks and
responsibilities [30,32]. However, location and identiﬁcation of exper-
tise is only part of the challenge. Even if organizations are successful at
providing accurate and comprehensive expertise directories to their
employees, the selection of experts is another challenging decision for
organization members [27]. Distinct from the location and identiﬁca-
tion of relevant expertise, expert selection refers to choosing from
among the identiﬁed possibilities the most appropriate experts to
consult with. Such decision requires an evaluation of the experts based
on knowledge that is often not available to the decision maker.

This paper focuses on the expert selection problem, which is of
particular relevance in an environment where communication is
mediated by technology, where employees are not collocated, may be
unfamiliar with each other, or have limited knowledge of each other's
expertise. IT-based expertise locator systems can help employees
locate and select experts. Expertise locator systems are tools aimed at
supporting the location of expertise within the organization, ranging
from online white pages backed by user proﬁles to more sophisticat-
ed Web and email mining systems, automated proﬁling systems, and
use of various intelligent agents and social computing tools [2].
Industry examples include Oracle's Beehive collaboration software,
speciﬁc modules within Microsoft's SharePoint, and IBM's BluePages.
A key objective of expertise locator systems is to provide users
with information that effectively enables not only locating expertise
but also deciding and selecting among relevant experts [30]. To
facilitate the design of such systems it is necessary to identify which
information can be useful in deciding among experts whom the

D. Nevo et al. / Decision Support Systems 53 (2012) 482–489

483

Knowledge 
Retrieval 

vs. 

Knowledge 
Allocation

Expert 
Selection

Assessment of:

Expertise

+

Network Ties

+ 

Personal 

Characteristics

Fig. 1. Knowledge demands for expert selection.

knowledge seeker is not personally familiar with. Consequently, in
this study we examine the attributes of the experts that expertise
seekers may use in making their selection decision.

For the conceptual foundation of this study, we rely on several
bodies of literature. First, transactive memory theory is a theory of
expertise location and coordination [22,43]. As groups are formed,
their members evaluate each other's knowledge and expertise and
encode this information in directories of meta-memory, indicating
who knows what within the group. When new knowledge enters the
group, it is allocated to the group's expert on the topic. Similarly
when knowledge is required beyond one's own area of expertise, the
group's expert on the topic is approached to obtain this knowledge
[43]. Transactive memory theory provides two important foundations
for this study. First, the use of meta-memory to locate and coordinate
expertise within the group can be utilized in technology-mediated
environments [7,18,32,34]. Second, transactive memory theory de-
ﬁnes two important contexts which we study in this paper:
knowledge retrieval – searching an answer from an expert; and
knowledge allocation – selecting an expert to transfer new knowledge
to. However, because the expertise selection problem discussed in
this paper may also apply to cases where people seek expertise
outside their group, from unfamiliar sources, and on an ad hoc basis
we employ a broader foundation to study the expertise selection
decision, as explained in the next section.

The objective of the study presented in this paper is thus to provide a
better understanding of the relative importance of expert attributes given
knowledge retrieval versus knowledge allocation objectives. Although
this investigation focuses on human-to-human information sharing,
technology can play an important role in enabling the sharing of
expertise by supporting the location of expertise and decision of what
experts to approach, and by mediating the sharing process. Indeed,
without technology, such sharing of information would be greatly
limited, as employees may be unaware of expertise which exists
elsewhere in the organization and therefore will have limited access
to this expertise. In this context, we believe that this study can offer
an important contribution in understanding the information required
by knowledge workers in order to decide where to look for
knowledge or whom to allocate knowledge. This understanding in
turn can help better determine the requirements of expertise locator
systems and guide the design of interfaces for such systems.

knowledge about the person's expertise, its value and cost [4]. Second,
knowledge of any pre-existing relationship between the expert and the
expertise seeker is also of relevance. For example, depending on the
expertise sought, an evaluation of strong versus weak network ties may
take place, where strong network ties indicate those individuals close to
the expertise seekers and are generally thought to facilitate the transfer of
tacit knowledge. Weak ties indicate those individuals not directly linked
to the expertise seeker, and as such enable access to a wider and richer
knowledge base, offering value in terms of acquiring new knowledge [21].
Third is knowledge of particular attributes of the expert, such as the
expert's willingness to help, ability to communicate their knowledge, or
other personal characteristics [e.g. 9,39].

Studying these three types of knowledge within a decision
context, there may be differences in the relative importance of
speciﬁc expert attributes for making a knowledge retrieval decision
versus a knowledge allocation decision. Transactive memory theory
deﬁnes knowledge retrieval as the process in which a member of the
group identiﬁes a need for knowledge. That person will then evaluate
his or her own “feeling of knowing” before searching for the group's
expert on the topic [43]. The literature reviewed identiﬁes a person's
expertise as most important for retrieving knowledge from that
person. An expert's knowledge of others' expertise, frequent and
effective communications between an expert and the knowledge
seeker, and knowing and valuing the knowledge possessed by the
expert are important factors in the knowledge retrieval decision
[4,15,23]. Hence we expect that attributes contributing to the percep-
tions of a person's expertise will be perceived as most important for
knowledge retrieval.

Knowledge allocation refers to a situation in which a member of the
organization obtains knowledge that may be relevant to others and
needs to locate the best person (or persons) to convey/transmit this
knowledge to [43]. Consider, as an example, a sales person who
obtains some strategic information concerning a competitor (for
example the development of a new product or targeting a new
market) and wishes to forward that knowledge to the most suitable
person within the organization. The sales person may need to select
among several individuals within the organization, and may require
speciﬁc knowledge to make this allocation decision.1 In expertise
literature, knowledge allocation has been rarely studied in and of

2. Foundation

We reviewed the literature on expertise selection [e.g. 4,9,27,29–
31,37,45], knowledge transfer [19–21,40], transactive memory [5,7,
15,16,18,22,23,28,32,34,35,43], and information quality [39,42] from the
perspective of making a decision about experts' selection. Synthesizing
this literature we found that three types of knowledge are used to make
decisions about the selection of experts, as illustrated in Fig. 1. First is the

1 We acknowledge that some members of the organization by their role deﬁnition
may be viewed as possessing expertise or as requiring speciﬁc knowledge. Nevo and
Wand [32] referred to this distinction as required role knowledge versus non-required
instance knowledge. Indeed there may be situations in which one is required to
allocate knowledge on a need basis (for example to a department manager). However,
in this paper our focus is on situations in which one faces a choice among a subgroup of
potential experts and a selection decision is warranted, regardless of how this
subgroup is identiﬁed (be it role knowledge, instance knowledge, or both). In other
words, we do not deal with the situation in which only a single person possesses the
required expertise.

484

D. Nevo et al. / Decision Support Systems 53 (2012) 482–489

itself. Examining related literature on knowledge transfer and on
contributions to online communities of practice indicates that
reciprocity expectations and norms play a key role in knowledge
contributions and transfer [20,40].

Rooted in social exchange theory [3], expected reciprocity in the
context of knowledge transfer has been deﬁned as a probabilistic
calculation that the beneﬁts from the exchange will outweigh the risk
that it will not be reciprocated [19]. From this point of view, in the
context of knowledge allocation, one is expected to select an expert to
allocate knowledge to base on knowing that he or she would be able
to retrieve the knowledge as needed, or that this knowledge could be
used to beneﬁt the organization. Hence we expect that attributes
contributing to reciprocity expectations will be perceived as most
important for knowledge allocation.

2.1. Hypotheses

The objective of this study is to understand the use of expert
attributes in the selection decision under two contexts — knowledge
retrieval versus knowledge allocation. For the reasons explained
above, we expect differences in the perceived importance of
attributes in each of the two contexts. To develop our hypotheses,
we begin by identifying a set of expert attributes used in the selection
decision. According to the transactive memory theory, information on
the subject and location of knowledge within the group (i.e. who
knows what) is needed [35,43]. In addition, as discussed above, other
knowledge may be needed to identify the suitable expert for a given
task, for example perceptions of each other's reliability, competence,
and trust [1,23,35]. Encoding such information is all the more
important in the technology-mediated environment to compensate
for the lack of face-to-face communications and familiarity [32].

The most prominent attributes identiﬁed in the transactive
memory and related literature concern perceptions of the credibility,
trustworthiness, and the level of expertise and depth of knowledge of
team members (e.g. [1,5,23,31,35]). We rely on related literature to
operationalize these attributes for the technology environment.
Speciﬁcally, Wathen and Burklell [41] link credibility with trustwor-
thiness and expertise. Mayer et al. [25] in turn associate trustworthi-
ness with a person's ability (or competence), benevolence, and
integrity. Whitener et al. [44] further note that a person's perception
of the trustworthiness of others is affected by attributes of the
communications between them,
including the frequency of the
communication, the adequacy of the explanations provided, and the
openness of the communication. Finally, assessing trustworthiness
can also be supported by information on the social network of the
expert. For example, information on the network ties that lie between
the expert and the expertise seeker may lead to trust through
common ties [6,21]. With respect to expertise, we note that beyond
identifying a person's expertise in a speciﬁc domain, Cross and
Sproull [8] also identiﬁed referrals as an important type of actionable
knowledge and part of a person's expertise.

Building on the above, in our study of knowledge allocation versus
retrieval, we study the relative importance of the following ﬁve
attributes2:

(1) Willingness to help: representing the potential expert's willing-

ness to help the expertise seeker.

(2) Communications skills: representing the ability of the potential
to clearly communicate their knowledge to the

expert
expertise seeker.

2 Note that, while our hypotheses focus on ﬁve speciﬁc attributes, our ﬁndings could
be generalized to other attributes representing expertise and reciprocity. We discuss
the generalizability of our ﬁndings later in the last section of the paper.

(3) Network ties to the respondent: representing the network
distance (i.e. degrees of separation) between the expertise
seeker and the potential expert.

(4) Self-identiﬁed expertise level: representing the extent that the
potential expert feels he or she has expertise in the domain of
the knowledge.

(5) Knowledge of others' expertise: representing the ability of the
potential expert to point in the direction of other experts in the
domain.

Referring back to Fig. 1, the above attributes span knowledge on a
person's expertise, network ties to the respondent, and personal
characteristics.

As discussed earlier in this paper we expect attributes representing
expertise to be perceived as more important for knowledge retrieval
than knowledge allocation. Accordingly we hypothesize that:

H1. A potential expert's self-rated expertise and knowledge of others'
expertise will be perceived as more important for knowledge
retrieval than for knowledge allocation.

We expect attributes related to reciprocity expectations to be
perceived as more important for knowledge allocation. Kachra and
White [19] observed that expected reciprocity is related to strong
social relationships and perceived competition. Hence, we expect
knowledge of a potential expert's social ties to the expertise seeker
and of that potential expert's benevolence or willingness to help to be
more important in the allocation context. Accordingly,

H2. A potential expert's willingness to help and their network ties to
the expertise seeker will be perceived as more important for
knowledge allocation than for knowledge retrieval.

Finally we note that the potential expert's communication skills
can be linked both to allocation and retrieval as it has been identiﬁed
as a component of a person's expertise as well as a contributor for a
person's trustworthiness [44]. Therefore we do not expect to ﬁnd a
signiﬁcant difference in the importance assigned to a potential expert's
communications skills.

In the next section, we discuss the methodology used to test these

hypotheses.

3. Methodology

The above hypotheses focus on the trade-offs we expect re-
spondents (i.e., expertise seekers) to make in terms of experts'
attributes when engaging in knowledge allocation versus knowledge
retrieval decisions. A suitable methodology to explore such trade-offs
is conjoint analysis. Conjoint analysis is a multivariate technique
originating in mathematical psychology [13]. It is a decompositional
approach in understanding choices and decisions, relying on a basic
assumption that a person's preferences toward an alternative (such
as a product or a service or, in this study, a speciﬁc expert) can be
decomposed to derive the values the individual places on the
attributes of that alternative [11,14].

In conjoint analysis, an alternative is introduced in terms of a bundle
of its characteristics, or attributes. For example, instead of evaluating
various laptop computers, respondents are asked to evaluate various
combinations (bundles) of attributes of laptops, such as processor type,
screen size, weight, and price. Such combinations are termed proﬁles.
Each proﬁle contains a description of the attributes of a different
alternative and the speciﬁc values, or levels, assigned to each attribute
(in the laptop example, one proﬁle example can be: processor: Intel
Core i3, screen size: 14″, weight: 5lbs, price: $450). The goal of conjoint
analysis is to identify the relative importance (and thus the trade-offs)
placed by respondents on the speciﬁc attributes during the decision-
making process.

D. Nevo et al. / Decision Support Systems 53 (2012) 482–489

485

Conjoint analysis provides two main measures: part-worth utility
estimates and importance weights of the attribute. The part-worth
utility estimates indicate the relation between each of the attributes'
levels and the preferences of the individual. Positive values mean that
the attribute's level is positively related to preference. The impor-
tance values represent the relative importance of each attribute in the
overall preference order of the individual.

Conjoint analysis can be used to study the trade-offs people are
willing to make between attributes of each alternative, to identify the
overall beneﬁts of different alternatives, to estimate the relative
importance of attributes of alternatives, and to estimate whether a
particular attribute has signiﬁcance in making a choice [36]. It was
chosen as the method for this study because it closely mimics our
phenomenon of interest — the expert selection decision. When
selecting experts, individuals choose a person rather than speciﬁc
attributes of a person. Similarly, the real life decision which we study
entails the evaluation of bundles as opposed to the evaluation of
individual attributes. Nevertheless, such attributes play an important
role in driving the selection of experts and hence a decompositional
approach which deduces the value of individual attributes from the
evaluation of the bundle as a whole is called for. Using conjoint
analysis in the context of this study can allow us to understand the
trade-offs that people make between different attributes of the expert
and the importance of speciﬁc attributes in the decision process.

There are several other beneﬁts for using conjoint analysis in a
decision-making context over compositional, self-explicating methods
(such as traditional surveys) that ask people to state the desirability
and importance of speciﬁc attributes. First,
in conjoint analysis,
decision makers are faced with options that vary across two or more
attributes and therefore are forced to make trade-offs that more closely
imitate real life decisions. Second, in the self-explicating process, when
responding to questions such as ‘how important is attribute A to you?’,
respondents might provide the socially desirable answer rather than
their true valuation of the attribute (for example, a person may state
that job satisfaction is more important than salary, but in reality might
choose the job with the higher salary over the more satisfying one).
Third, if some attributes are correlated, for example gas mileage and
economy of a car, double counting is more likely to occur in the self-
explicating method than in conjoint analysis. Finally, conjoint analysis
allows greater ﬂexibility in deﬁning the model and does not limit the
researcher to deﬁne a linear relationship between speciﬁc levels of
attributes (e.g. three different price levels) and a person's preference
order, as is the case for most self-explicating models. Thus conjoint
analysis enables ﬁtting the best model for the relative desirability of
levels of each of the attributes [12,26].

The following subsections discuss ﬁrst the study's design (ques-
tionnaires used, expert proﬁles provided, and procedures conducted)
and then the sample of respondents.

3.1. Design of study

In accordance with our study's objective and hypotheses, the
conjoint analysis consisted of two parts, using two separate yet
identically designed web-based questionnaires (provided in the
Appendix). One questionnaire focused on eliciting the relative
importance of attributes in the context of knowledge allocation, and
the other focused on eliciting the relative importance of attributes in
the context of knowledge retrieval. Each questionnaire used an
appropriate scenario as shown below. The scenarios were presented
to respondents in random order.

Allocation: You have recently joined the sales team of SuperTech, a
company specializing in developing and marketing customer rela-
tionship management (CRM) systems. You are visiting one of the
company's largest clients, a chemical manufacturer. During a
conversation, the client's VP of Sales tells you about the difﬁculties

he is having in producing accurate sales forecasts and then
translating them into production forecasts. He tells you, “This is a
serious problem for us as we are always over or under producing
because we can't forecast demand. The interesting thing is that there
is no software package out there that will help us do that. I'm telling
you, we would be the ﬁrst ones to buy something like that!” You have
just identiﬁed a potentially lucrative new business line for SuperTech.
This is not your area of expertise so you need to ﬁnd the right person
within your team to whom you can pass this information.
Retrieval: You have recently joined the sales team of SuperTech, a
company specializing in developing and marketing customer rela-
tionship management (CRM) systems. SuperTech has been working
extensively to secure a large contract with a major bank. Over the
past year, the sales team has been involved in numerous product
demonstrations and requirements gathering sessions, and it ﬁnally
looks like the prospect is almost ready to sign. This would be a major
win for the company and all eyes are on this deal. As a new member
of this team you meet with the client's CIO, who tells you the
following: “I love the product and I think it's going to work for us but
I'm very concerned that SuperTech does not have much experience in
Financial Services. I want to speak to one of your existing customers
who is in our industry and who operates under a similar business
model. If you can get me this information, we have a deal.” You head
back to the ofﬁce and decide to look for expertise from within the
sales team.

After reading each scenario, respondents were asked to evaluate
proﬁles of potential experts and either assess their likelihood of
passing the information to them (knowledge allocation) or assess
their likelihood of approaching them with respect to obtaining
information (knowledge retrieval).

The proﬁle of each potential expert consisted of the ﬁve attributes
described earlier in this paper. For example, the proﬁle description of
a potential expert may have appeared as follows:

- Knowledge of others' expertise: Yes
- Communications skills: Good
- Self-identiﬁed expertise level: High
- Willingness to help: No
- Network ties to you: Weak

The survey introduction included the deﬁnition for each attribute,
its possible values, and an example proﬁle similar to the one above.
In constructing the questionnaires, we used a fractional factorial
design [24,38]. If we deﬁne the attributes of interest as the ﬁve
attributes introduced earlier in this paper, and each attribute is
assigned two possible levels (e.g., yes/no, high/low), then a full
factorial design implies that all possible combinations of factors and
levels are reviewed by respondents, which in our case would be 25 or
32 proﬁles to evaluate. Utilizing a fractional factorial design allows for
the evaluation of a smaller number of proﬁles, in our case the eight
listed in Table 1.

The proﬁles were presented to respondents in a list format
(similar to the above example) and for each proﬁle, respondents were
asked to indicate their likelihood of selecting the expert described in
the proﬁle for the particular purpose of consulting or informing. We
used an 11-point scale to evaluate the likelihood of selecting the
expert described in the proﬁle to either pass knowledge to
(allocation) or consult for knowledge (retrieval). The scale ranged
from “not at all likely” on the one end to “will certainly pass the
knowledge” (allocation) or “will certainly consult” (retrieval) on the
other. The center point represented a neutral view.

In addition to the eight proﬁles used to estimate the model, two
more validation proﬁles were included in the survey [14]. The
validation proﬁles were similar in form to those described in Table 1
and respondents evaluated them in the same manner they did to the
other proﬁles. The validation proﬁles, however, were not used in the

486

Table 1
Conjoint proﬁles.

Attribute

D. Nevo et al. / Decision Support Systems 53 (2012) 482–489

Levels

Proﬁle 1

Proﬁle 2

Proﬁle 3

Proﬁle 4

Proﬁle 5

Proﬁle 6

Proﬁle 7

Proﬁle 8

Knowledge of others' expertise
Communications skills
Self-identiﬁed expertise level
Willingness to help
Network ties to you

Yes/no
Good/poor
High/low
Yes/no
Strong/weak

No
Poor
Low
No
Strong

No
Good
High
No
Weak

Yes
Good
High
Yes
Strong

Yes
Poor
Low
Yes
Weak

Yes
Poor
High
No
Weak

No
Poor
High
Yes
Strong

No
Good
Low
Yes
Weak

Yes
Good
Low
No
Strong

Fig. 2. Characteristics of respondents.

actual ﬁtting of the regression model but instead were used to test the
predictive ability of the derived model (comparing predicted and
actual values). Finally, one repeated proﬁle was also included for
reliability purposes, to ensure responses were consistent for the two
identical proﬁles. Overall respondents evaluated eleven proﬁles under
each task and using an 11-point scale. The least squares regression
model was used as the estimation method, as is common in many
conjoint studies.

3.2. Respondents

We sent online invitations to a random sample of 1000 English
speaking, North-American members of a LinkedIn Web 2.0 commu-
nity with approximately 12,000 members worldwide. Members of
this community are all professionals who share an interest in various
aspects of Web2.0. A total of 199 responses were received of which
180 were valid and used in the conjoint analysis, for a ﬁnal response
rate of 18%. Such response rate is not uncommon for Web based
surveys. Further,
responses (180) is
acceptable for conjoint analysis studies [14]. The average respondent,
or expertise seeker, had slightly over 15 years of work experience and
had been working in his/her current position for about 3.5 years. Of
the total number of respondents, 24% were female and 76% were
male. Fig. 2 provides additional information on respondents in this
study in terms of their expertise seeking habits. As the ﬁgure shows,
the majority of respondents work in a team environment, actively
consult colleagues for knowledge outside of their own expertise, and
often use technology to locate expertise.

the absolute number of

4. Findings of conjoint study

Testing our hypotheses to study the difference between the
relative importance of attributes in the allocation and retrieval
processes, we followed two key steps. We ﬁrst computed, for each
respondent, the preference order of attributes under each of the two

scenarios, using the conjoint syntax in SPSS. We then followed with
within-subject testing of the difference in importance weights for the
two scenarios, as described below.

4.1. Conjoint analysis

For each respondent a regression model was estimated using eight
of the proﬁles (excluding the validation proﬁles), with the respon-
dent's rating as the dependent variable and attributes' levels as the
independent (dummy) variables. The results of these regressions
provided, for each respondent, part-worth utilities for each attribute's
level, representing its contribution to the overall utility assigned to
the various proﬁles by the respondent. An importance weight was
also calculated for each attribute based on the magnitude of its levels'
part-worth utilities; higher magnitude meaning the attribute is more
important to the respondent. At the end of this process, a preference
order of attributes and their importance (out of 100%) was obtained
for each respondent under each of the two scenarios.

As a measure of the quality of the conjoint model, Pearson
correlations were computed between the model estimated and actual
ratings of each proﬁle. The aggregated Pearson's R value for the
allocation scenario was 0.992 (signiﬁcance of 0.000) and for the
retrieval scenario, 0.987 (signiﬁcance of 0.000). In addition, as an
indication of the predictive ability of the model, similar correlations
were calculated for the two validation proﬁles which were not used
to estimate the regression model. The aggregated Pearson's R values
for the validation proﬁles were 0.781 (signiﬁcance of 0.000) for the
allocation context and 0.792 (signiﬁcance of 0.000) for the retrieval
context.3

On average, all attributes were perceived as important by survey
respondents with importance weights (on a percentage scale)

3 Pearson's R value for the validation proﬁles are generally expected to be somewhat

lower than those computed for the model.

D. Nevo et al. / Decision Support Systems 53 (2012) 482–489

487

ranging from 14% to 26%. However, because conjoint analysis is
conducted at the individual level (i.e. a preference model as estimated
for each respondent in the study),
it is not advisable to report
aggregated descriptive statistics of the conjoint results. To further
analyze the results we conducted within subject tests examining
changes in the relative importance placed on attributes under the two
study contexts.

4.2. Within-subject tests

Once importance weights were obtained for each respondent, we
conducted two within-subjects tests comparing the calculated
importance weights as well as the rank order of attributes under
the two scenarios. The ﬁrst test was conducted as a paired sample t-
test. This test, shown in Table 2, computed difference scores based on
the importance weights assigned by each respondent to each attribute
under the two scenarios presented in the study. Speciﬁcally, the
paired sample difference score – di – was computed as respondent i's
importance weight for the “willingness to help” attribute under the
knowledge allocation scenario minus respondent i's importance
weight for the “willingness to help” attribute under the knowledge
retrieval scenario. The results of this test are presented in Table 2
showing a statistically signiﬁcant difference in the importance
weights assigned to four of the ﬁve attributes. The measurement
scale for importance weights is the percentage scale, thus the value of
0.03 next to the “willingness to help” attribute in Table 2 represents a
3% increase in the importance assigned to this attribute under the
allocation context versus the retrieval context. As seen in Table 2, the
attributes “willingness to help” and “network ties to the respondent”
were deemed more important
for knowledge allocation. The
attributes “self-identiﬁed expertise” and “awareness of other re-
sources” were deemed more important for knowledge retrieval.
There was no signiﬁcant difference in the importance assigned to the
“communication skills” attribute.

Note that the above test focuses on the importance weights
assigned to each attribute rather than on the rank order of attributes.
We conducted a second paired sample test on the ranking of
attributes, using the Wilcoxon signed rank sum test, and the results
are shown in Table 3. The Wilcoxon signed rank sum test is a non-
parametric test similar to a paired samples t-test, with the exception
that it does not assume a normal distribution. In terms of the rank
order of attributes, the same changes as above are seen for the
attributes “willingness to help”, “network ties to the respondent”, and
“self-identiﬁed expertise” but no signiﬁcant difference was found for
the ranking of the “awareness of others' expertise” attribute. In other
words, while the importance of this attribute is reduced when
considering knowledge allocation (as opposed to knowledge retriev-
al), its ranking has not signiﬁcantly changed.

Overall the within-subject tests conducted on the data obtained
through the conjoint analysis largely support our hypotheses
the
concerning the difference in the perceived importance of

Table 2
Results of a paired sample t-test of the importance weights of attributes in knowledge
allocation vs. knowledge retrieval.

Attribute

Increased
importance for

Mean difference
(allocation — retrieval)

p-value

Willingness to help
Communications skills
Network ties to

the respondent

Allocation
Non signiﬁcant
Allocation

Self-identiﬁed expertise
Awareness of

Retrieval
Retrieval

others' expertise

0.030
0.000
0.039

−0.044
−0.025

0.010
0.493
0.000

0.000
0.021

attributes in the two scenarios. We discuss the results of both studies
and their contributions next.

5. Discussion

Information technology has been proposed as a valuable tool to
support expertise location in organizations, but research is needed to
better understand the design of such systems. Accordingly, the
objective of this study was to explore the requirements of expertise
seekers in terms of the relative importance of expert attributes used in
the selection decision. We further focused on the difference in the
relative importance of attributes under different decision contexts.
Speciﬁcally we examined the attributes that individuals perceive as
important
in allocating knowledge versus those perceived as
important in retrieving knowledge. Our conjoint analysis study and
subsequent within-subject comparisons of the derived importance of
attributes supported our hypotheses about the relative importance of
attributes for knowledge allocation and for knowledge retrieval.
Utilizing the conjoint methodology which focuses on the trade-offs of
attributes made by respondents, we found that when selecting a
potential expert to whom knowledge will be allocated, respondents
placed greater importance on their own relationships with that
person, increasing the importance they assigned to the person's
willingness to help and to their social ties with that person. On the
other hand, when it came to knowledge retrieval, a person's expertise
and awareness of others' expertise were more important.

Generalizing on our results we note that attributes conveying the
expertise of a person were perceived as more important for knowledge
retrieval, whereas attributes relating to reciprocity expectations were
more important for knowledge allocation. The one attribute that was
related to both expertise and reciprocity (i.e. the communication
skills of the source) was perceived as equally important under both
contexts.

This paper contributes toward a more effective use of IT to support
expertise location and coordination in organizations. The literature so
far has explored knowledge retrieval and its demands in terms of the
design of information systems. In this paper we argue that expertise
location and selection goes beyond knowledge retrieval and that
expertise seekers may have other objectives, such as knowledge
allocation. Unfortunately, much less attention has been given in the IS
literature to the knowledge allocation process, even though organi-
zation members often require support in allocating knowledge.
Furthermore,
the transactive memory literature has identiﬁed
knowledge allocation as important for the effective coordination
and utilization of expertise (e.g. [18,23,34]), highlighting the need to
better understand and support this process.

As a conceptual contribution, we have opened up the allocation
process for future studies by showing that knowledge allocation
considerations are non-trivial. In fact, our results create an important
and interesting link between the allocation process and the more
strategic decision of knowledge contributions and knowledge
transfer, showing that people place greater importance on reciprocity
attributes in the allocation context than in the retrieval context. From
a practical standpoint we have demonstrated the need to customize
the interface of any IT intended to support expertise location and
selection by allowing its users to obtain information on task-relevant

Table 3
Results of a Wilcoxon signed rank sum test on the rank order of attributes in
knowledge allocation vs. knowledge retrieval.

Attribute

Ranked higher for

p-value

Willingness to help
Communications skills
Network ties to the respondent
Self-identiﬁed expertise
Awareness of others' expertise

Allocation
Non signiﬁcant
Allocation
Retrieval
Non signiﬁcant

0.001
0.699
0.003
0.000
0.211

488

D. Nevo et al. / Decision Support Systems 53 (2012) 482–489

attributes as needed. Furthermore, to the extent that representing
these attributes in an information system might be costly, we have
provided organizations with insights on which investments are more
important under different contexts.

This study is not without limitations. Most notably, we presented
respondents with two speciﬁc hypothetical scenarios and only a
subset of a host of potential attributes was explored. Our choice of
scenarios could possibly bias the importance evaluation of speciﬁc
attributes and additional scenarios should be investigated in the
future. With respect to the set of attributes employed, we do not
claim that this subset is better than or worse than other potential
choices of attributes, but rather we show that the use of speciﬁc
attributes (such as those utilized in our study) can impact expertise
selection. Future work may explore additional attributes and in a
more real-life decision setting. Furthermore, our survey respondents
are members of a Web2.0 community and are somewhat homoge-
nous in their knowledge sharing habits. The respondents also have
many years of experience which may bias their perception of
importance of some attributes, most notably network ties. However,
we believe that this sample was useful for this study since the
subjects possess the domain expertise needed for the conjoint
analysis. Finally, our experimental scenarios involved taking knowl-
edge from, or delivering knowledge to, a third party that may be
external to the organization. In some cases one may perceive some
organizational variables (such as organizational norms or organiza-
tional location) that may impact the relative importance assigned to
attributes. Such factors may be investigated in future studies.

Several areas still remain unexplored. The contribution of our
study can be further tested when the IT is actually implemented and
the expertise selection process is carefully tracked. Studies can
compare the selection of experts with and without proper IT support
to identify the role played by the improved design of the IT suggested
in this study. Additional attributes may be further explored to offer
more insights to technology designers. While our study did not
examine attributes of the expertise seeker (such as organizational
tenure and expertise), future studies should examine how variations
in the attributes of the expertise seeker affect their search behavior.
Third, we identiﬁed “willingness to help” as an important attribute as
perceived by the expertise seeker. This points to interesting issues to
explore in future studies, such as the motivation behind willingness
to help and whether knowledge of the speciﬁc motivation for helping
may impact the expertise seekers' selection of experts. Finally,
asymmetries may exist in the number of experts selected for retrieval
versus allocation. For example, because of different costs involved
with each process. An interesting direction for future research would
be to explore how expertise seekers decide on the number of experts
to include in retrieval and allocation decisions.

Appendix A. Supplementary data

Supplementary data to this article can be found online at doi:10.

1016/j.dss.2012.03.005.

References

[1] A.E. Akgun, J. Byrne, H. Keskin, G.S. Lynn, S.Z. Imamoglu, Knowledge networks in
new product development projects: a transactive memory perspective, Informa-
tion Management 42 (8) (2005) 1105–1120.

[2] I. Becerra-Fernandez, Searching for experts on the Web: a review of contemporary

expertise locator systems, ACM T on Internet Technology 6 (4) (2006) 333–355.

[3] P.M. Blau, Exchange and Power in Social Life, Wiley, New York, 1964.
[4] S.P. Borgatti, R. Cross, A relational view of information seeking and learning in

social networks, Management Science 49 (4) (2003) 432–445.

[5] D.P. Brandon, A.B. Hollingshead, Transactive memory systems in organizations:
matching tasks, expertise, and people, Organization Science 15 (6) (2004)
633–644.

[6] R.S. Burt, M. Knez, Kinds of third-party effects on trust, Rationality and Society 7

(3) (1995) 255–292.

[7] S.Y. Choi, H. Lee, Y. Yoo, The impact of information technology and transactive
memory systems on knowledge sharing, application, and team performance: a
ﬁeld study, MIS Quarterly 34 (4) (2010) 855–870.

[8] R. Cross, L. Sproull, More than an answer: information relationships for actionable

knowledge, Organization Science 15 (2004) 446–462.

[9] K. Ehrlich, Locating expertise: design issues for an expertise locator system, in: M.
Ackerman, P. Volkmar, W. Volker (Eds.), Beyond Knowledge Management:
Sharing Expertise, MIT Press, Cambridge, 2003.

[10] D. Gilmour, How to ﬁx knowledge management, Harvard Business Review 81

(10) (2003) 16–17.

[11] P.E. Green, V.R. Rao, Conjoint measurement for quantifying judgmental data,

Journal of Marketing Research 8 (3) (1971) 355–363.

[12] P.E. Green, V. Srinivasan, Conjoint analysis in marketing: new developments
with implications for research and practice, Journal of Marketing 54 (4) (1990)
3–19.

[13] P.E. Green, V. Srinivasan, Conjoint analysis in consumer research: issues and

outlook, Journal of Consumer Research 5 (1978) 103–123.

[14] J.F. Hair, R.E. Anderson, R.L. Tatham, W.C. Black, Multivariate Data Analysis,

Prentice-Hall, Englewood Cliffs, NJ, 2009.

[15] A.B. Hollingshead, Retrieval processes in transactive memory systems, Journal of

Personality and Social Psychology 74 (1998) 659–671.

[16] A.B. Hollingshead, Cognitive interdependence and convergent expectations in
transactive memory, Journal of Personality and Social Psychology 81 (6) (2001)
1080–1089.

[17] Z. Huang, H. Chen, F. Guo, J.J. Xu, S. Wu, W.H. Chen, Expertise visualization: an
implementation and study based on cognitive ﬁt theory, Decision Support
Systems 42 (3) (2006) 1539–1557.

[18] P. Jackson, J. Klobas, Transactive memory systems in organizations: implica-
tions for knowledge directories, Decision Support Systems 44 (2) (2008)
409–424.

[19] A. Kachra, R.E. White, Know-how transfer: the role of social, economic/-
competitive, and ﬁrm boundary factors, Strategic Management Journal 29 (4)
(2008) 425–445.

[20] A. Kankanhalli, B.C.Y. Tan, K.K. Wei, Contributing knowledge to electronic
investigation, MIS Quarterly 29 (1)

knowledge repositories: an empirical
(2005) 113.

[21] D.Z. Levin, R. Cross, The strength of weak ties you can trust: the mediating role of
trust in effective knowledge transfer, Management Science 50 (11) (2004)
1477–1490.

[22] K. Lewis, Measuring transactive memory systems in the ﬁeld: scale development

and validation, Journal of Applied Psychology 88 (4) (2003) 587–604.

[23] K. Lewis, Knowledge and performance in knowledge-worker teams: a longitu-
dinal study of transactive memory systems, Management Science 50 (11) (2004)
1519–1533.

[24] J.J. Louviere, Analyzing Decision Making: Metric Conjoint Analysis, Sage

Publications, Beverly Hills, CA, 1988.

[25] R.C. Mayer, J.H. Davis, F.D. Schoorman, An integrative model of organizational

trust, Academy of Management Review 20 (1995) 709–734.

[26] D. McCullough, A user's guide to conjoint analysis, Marketing Research 14 (2)

(2002) 18.

[27] D.W. McDonald, M.S. Ackerman, Just talk to me: a ﬁeld study of expertise
location, Proc. of the 1998 ACM Conference on Computer-Supported Cooperative
Work (CSCW'98), 1998, pp. 315–324.

[28] R.L. Moreland, L. Myaskovsky, Exploring the performance beneﬁts of group
training: transactive memory or improved communication? Organizational
Behavior and Human Decision 82 (1) (2000) 117–133.

[29] M.J. Muller, K. Ehrlich, S. Farrell, Social tagging and self-tagging for impression
management, IBM Research technical report TR 06–02, http://domino.watson.ibm.
com/cambridge/research.nsf/c9ef590d6d00291a85257141004a5c19/
27658d7dcf7e8cce852572330070244d/$FILE/TR2006-2.pdf2011veriﬁed July 2011.
[30] D. Nevo, I. Benbasat, Y. Wand, Who knows what, Wall Street Journal/ Sloan

Management Review, October 2009.

[31] D. Nevo,

I. Benbasat, Y. Wand, Exploring meta-knowledge for knowledge
management systems: A Delphi study, International Conference on Information
Systems, 2003, pp. 439–449.

[32] D. Nevo, Y. Wand, Organizational memory information systems: a transactive

memory approach, Decision Support Systems 39 (4) (2005) 549–562.

[33] D. Obstfeld, Social networks, the tertius iungens orientation, and involvement in

innovation, Administrative Science Quarterly 50 (1) (2005) 100–130.

[34] I. Oshri, P. Van Fenema, J. Kotlarsky, Knowledge transfer in globally distributed
teams: the role of transactive memory, Information Systems Journal 18 (6)
(2008) 593–616.

[35] D.L. Rulke, D. Rau, Investigating the encoding process of transactive memory
development in group training, Group and Organization Management 25 (4)
(2000) 373.

[36] M. Ryan, S. Farrar, Using conjoint analysis to elicit preferences for health care, BMJ

320 (2000) 1530–1533.

[37] L. Terveen, W. Hill, Beyond recommender systems: helping people help each

other, in: J. Carroll (Ed.), HCI in the New Millennium, Addison-Wesley, 2001.

[38] A. Tiwana, M. Keil, R.G. Fichman, Information systems project continuation in
escalation situations: a real options model, Decision Sciences 37 (3) (2006)
357–391.

[39] R.W. Wang, D.M. Strong, Beyond accuracy: what data quality means to data

consumers, Journal of Management Information Systems 12 (4) (1996) 5.

[40] M. Wasko, S. Faraj, Why should i share? Examining knowledge contribution in

electronic networks of practice, MIS Quarterly 29 (1) (2005) 1–23.

D. Nevo et al. / Decision Support Systems 53 (2012) 482–489

489

[41] C.N. Wathen, J. Burkell, Believe it or not: factors inﬂuencing credibility on the
Web, Journal of the American Society for Information Science and Technology 53
(2) (2002) 134–144.

[42] S. Watts, G. Shankaranarayanan, A. Even, Data quality assessment in context: a

cognitive perspective, Decision Support Systems 48 (1) (2009) 202–211.

[43] D.M. Wegner, Transactive memory: a contemporary analysis of the group mind,
in: B. Mullen, G.R. Goethals (Eds.), Theories of Group Behavior: 185–208,
Springer-Verlag, New York, 1986.

[44] E.M. Whitener, S.E. Brodt, M.A. Korsgaard, J.M. Werner, Managers as Initiators of
Trust: An Exchange Relationship Framework for Understanding Managerial
Trustworthy Behavior. The Acad. of Management Rev. 1998, 23(3):513–530

[45] D. Yimam-Seid, A. Kobsa, Expert-ﬁnding systems for organizations: problem and
domain analysis and the DEMOIR approach, Journal of Organizational Computing
and Electronic Commerce 13 (1) (2003) 1–24.

Dorit Nevo is an Associate Professor of Information Systems at York University's
Schulich School of Business. She received her Ph.D. in Management Information
Systems from the University of British Columbia and her M.Sc. in Economics from the
Technion — Israel Institute of Technology. Her current research interests include
expertise location, social computing, and the impact of technology on individuals and
teams.

Izak Benbasat is a Fellow of the Royal Society of Canada and CANADA Research Chair in
Information Technology Management at the Sauder School of Business, University of
British Columbia, Canada. He currently serves on the editorial boards of Journal
Management Information Systems and Information Systems Journal. He was editor-in-
chief of Information Systems Research, editor of the Information Systems and Decision
Support Systems Department of Management Science, and a senior editor of MIS
Quarterly. He became a Fellow of the Association for Information Systems (AIS) in
2002, received the LEO Award for Lifetime Exceptional Achievements in Information
Systems from AIS in 2007, and was conferred the title of Distinguished Fellow by the
Institute for Operations Research and Management Sciences (INFORMS) Information
Systems Society in 2009.

Yair Wand is CANFOR Professor of MIS at the Sauder School of Business, The University
of British Columbia, Canada. He received his D.Sc. in Operations Research from The
Technion (Israel) and his M.Sc. in Physics from the Weizmann Institute (Israel). His
current research interests include theoretical foundations for information systems
analysis and design, development and evaluation of system analysis methods, and
conceptual modeling. His published work includes articles in ACM Transactions on
Database Systems, Communications of the ACM,
IEEE Transactions on Software
Engineering, Information Systems Research, Journal of Information Systems, and the
Requirements Engineering Journal.

